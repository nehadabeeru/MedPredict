{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dq9_r7XLx588","outputId":"35561bd8-90d0-4523-d58c-6772cd75e406","executionInfo":{"status":"ok","timestamp":1733522492458,"user_tz":480,"elapsed":112920,"user":{"displayName":"Naveen Yadav Gongati","userId":"00221391503133306453"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount the Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import StratifiedKFold\n","from torch.utils.data import Dataset\n","import os\n","import itertools\n","import json\n","\n","# Load and preprocess the dataset\n","file_path = '/content/drive/Shared drives/DATA298B/Readmission/final_enhanced_patient_summaries.json'\n","\n","# Load JSON data and convert to DataFrame\n","with open(file_path, 'r') as f:\n","    data = pd.DataFrame([json.loads(line) for line in f])\n","\n","# Extract text data and labels\n","data['text'] = data['enhanced_summary']\n","data['label'] = data['readmission_status'].apply(lambda x: 1 if x == 'yes' else 0)\n","\n","# Initialize the tokenizer\n","tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n","\n","# Define a custom dataset class with contiguous tensors\n","class ReadmissionDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        # Ensure all tensors in encodings and labels are contiguous\n","        self.encodings = {key: torch.tensor(val).contiguous() for key, val in encodings.items()}\n","        self.labels = torch.tensor(labels).contiguous()\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item['labels'] = self.labels[idx]\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Define hyperparameters to tune\n","hyperparameters = {\n","    'num_train_epochs': [4],\n","    'per_device_train_batch_size': [16],\n","    'learning_rate': [3e-5],\n","}\n","\n","# Create all combinations of hyperparameters\n","param_combinations = list(itertools.product(*hyperparameters.values()))\n","\n","# Stratified cross-validation setup\n","k_folds = 5\n","skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n","metrics_per_combination = {}\n","\n","# Folder to save the model\n","model_save_path = '/content/drive/Shared drives/DATA298B/Readmission/Dataset/saved_model9'\n","os.makedirs(model_save_path, exist_ok=True)\n","\n","# Perform cross-validation with hyperparameter tuning\n","for param_idx, params in enumerate(param_combinations):\n","    print(f\"\\nTraining with hyperparameters: {params}\")\n","\n","    num_train_epochs, per_device_train_batch_size, learning_rate = params\n","    fold_metrics = []\n","\n","    for fold, (train_index, test_index) in enumerate(skf.split(data, data['label'])):\n","        print(f\"\\nFold {fold + 1}/{k_folds}\")\n","\n","        # Split the data\n","        train_texts, test_texts = data['text'].iloc[train_index].tolist(), data['text'].iloc[test_index].tolist()\n","        train_labels, test_labels = data['label'].iloc[train_index].tolist(), data['label'].iloc[test_index].tolist()\n","\n","        # Tokenize\n","        train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n","        test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)\n","\n","        # Create dataset\n","        train_dataset = ReadmissionDataset(train_encodings, train_labels)\n","        test_dataset = ReadmissionDataset(test_encodings, test_labels)\n","\n","        # Load the model\n","        model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\n","\n","        # Make all model parameters contiguous\n","        for param in model.parameters():\n","            param.data = param.data.contiguous()\n","\n","        # Set up training arguments\n","        training_args = TrainingArguments(\n","            output_dir=f'./results_fold_{fold}',\n","            num_train_epochs=num_train_epochs,\n","            per_device_train_batch_size=per_device_train_batch_size,\n","            per_device_eval_batch_size=16,\n","            learning_rate=learning_rate,\n","            evaluation_strategy=\"no\",\n","            report_to=\"none\",\n","        )\n","\n","        # Define the Trainer\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=test_dataset,\n","        )\n","\n","        # Train the model\n","        trainer.train()\n","\n","        # Save the model after training in each fold\n","        model.save_pretrained(os.path.join(model_save_path, f'model_fold_{fold + 1}_params_{param_idx}'))\n","        tokenizer.save_pretrained(os.path.join(model_save_path, f'model_fold_{fold + 1}_params_{param_idx}'))\n","\n","        # Evaluate the model\n","        predictions = trainer.predict(test_dataset)\n","        pred_labels = predictions.predictions.argmax(-1)\n","\n","        # Calculate metrics\n","        report = classification_report(test_labels, pred_labels, output_dict=True)\n","        fold_metrics.append(report)\n","\n","    # Aggregate metrics for the hyperparameter configuration\n","    avg_metrics = {\n","        \"precision\": sum(d[\"weighted avg\"][\"precision\"] for d in fold_metrics) / k_folds,\n","        \"recall\": sum(d[\"weighted avg\"][\"recall\"] for d in fold_metrics) / k_folds,\n","        \"f1-score\": sum(d[\"weighted avg\"][\"f1-score\"] for d in fold_metrics) / k_folds,\n","        \"accuracy\": sum(d[\"accuracy\"] for d in fold_metrics) / k_folds,\n","    }\n","\n","    metrics_per_combination[param_idx] = avg_metrics\n","    print(f\"\\nAverage Metrics for combination {param_idx}:\")\n","    print(f\"Precision: {avg_metrics['precision']:.4f}\")\n","    print(f\"Recall: {avg_metrics['recall']:.4f}\")\n","    print(f\"F1-score: {avg_metrics['f1-score']:.4f}\")\n","    print(f\"Accuracy: {avg_metrics['accuracy']:.4f}\")\n","\n","# Find the best hyperparameter combination\n","best_combination_idx = max(metrics_per_combination, key=lambda k: metrics_per_combination[k]['f1-score'])\n","best_metrics = metrics_per_combination[best_combination_idx]\n","print(f\"\\nBest hyperparameter combination: {param_combinations[best_combination_idx]}\")\n","print(f\"Best F1-score: {best_metrics['f1-score']:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ee71f39634984fb38c0464a01377e65c","190d0599a94a48349b0cd42873d0970f","8bbb9f5deead4dbb988fae51643a902c","47ad6c09ff844505bc859fe5abf8bd79","b01d09cb75174a4cbef9694589123cef","cac1c701e1a443b889fc2ea8b156b0ce","cf0c19da28994ca4a8be500b605668c3","6d27f9dd6e304c498755b0d9e334358b","1a647b4e69b64f258bb111c55158e358","956fd3b66904427db3d419540140a30b","e71536b652ab4b34ad6dde342b4c0aa0"]},"id":"U1ZLOIU5V7oY","outputId":"3320125b-3dec-4072-820d-9a9be657d5b2"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Training with hyperparameters: (4, 16, 3e-05)\n","\n","Fold 1/5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee71f39634984fb38c0464a01377e65c","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [248/248 07:36, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Fold 2/5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [248/248 06:07, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Fold 3/5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [248/248 07:39, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Fold 4/5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='172' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [172/248 05:13 < 02:20, 0.54 it/s, Epoch 2.76/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [248/248 07:42, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Fold 5/5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [248/248 07:38, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Average Metrics for combination 0:\n","Precision: 0.9658\n","Recall: 0.9649\n","F1-score: 0.9648\n","Accuracy: 0.9649\n","\n","Best hyperparameter combination: (4, 16, 3e-05)\n","Best F1-score: 0.9648\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from transformers import XLNetTokenizer, XLNetForSequenceClassification\n","\n","# Specify the number of folds\n","num_folds = 5  # Adjust this based on the number of folds used during training\n","model_paths = [f'/content/drive/Shared drives/DATA298B/Readmission/Dataset/saved_model9/model_fold_{i+1}_params_0' for i in range(num_folds)]\n","\n","# Load the tokenizer\n","tokenizer = XLNetTokenizer.from_pretrained(model_paths[0])  # Use the tokenizer from any model\n","\n","# Example clinical notes for prediction\n","clinical_notes = [\n","\n","                  \"The patient is a 65-year-old female with a history of congestive heart failure and chronic obstructive pulmonary disease (COPD). She was admitted for acute exacerbation of COPD, presenting with severe shortness of breath and low oxygen saturation. During her hospital stay, her condition required frequent adjustments to her oxygen therapy and multiple high-dose steroid treatments. The discharge plan included oxygen therapy at home and follow-up in one week. However, she lives alone and expressed concerns about managing her medications and oxygen setup. Her last lab results showed borderline low sodium and elevated blood urea nitrogen, with fluctuating blood pressure readings. She also had a recent hospitalization three weeks ago for a similar issue.\",\n","                  \"The patient is a 45-year-old male with hypertension and Type 2 diabetes, who was admitted for routine monitoring after an elective orthopedic surgery. His hospital course was stable, with no complications, and he showed consistent improvement in mobility and pain control. Vital signs and lab results were within normal ranges at discharge. He was discharged with a home exercise plan and clear instructions on managing post-operative care, including regular check-ups with his primary physician. He has a strong support system at home, with family members who can assist with his care as needed. No significant health issues were noted at discharge.\",\n","                  \"The patient is a 50-year-old male with schizophrenia and Type 2 diabetes, admitted for hyperglycemia and dehydration. He was stabilized with insulin and rehydration during his stay. However, he has a history of non-adherence to medication, which complicates his diabetes management. He is being discharged with insulin therapy and has been referred for mental health follow-up, but he has a limited support system. His lab results at discharge were within normal ranges, but his history of inconsistent medication adherence and frequent admissions suggests a high risk of readmission.\",\n","                  \"The patient is a 55-year-old female with no significant prior medical history, admitted for knee replacement surgery. Her postoperative recovery was smooth, with no complications, and her vital signs remained stable throughout her stay. Physical therapy sessions showed good progress, and she was discharged with clear instructions for exercises and a follow-up with her orthopedic surgeon in two weeks. She has family support at home, and all necessary pain medications and supplies were arranged prior to discharge. Her final lab results were within normal limits, indicating a low risk of complications.\"\n","]\n","\n","\n","# Prepare inputs for the model\n","inputs = tokenizer(clinical_notes, truncation=True, max_length=512, padding=True, return_tensors='pt')\n","\n","# List to store predictions from each fold\n","all_predictions = []\n","\n","# Make predictions using each model\n","for model_path in model_paths:\n","    # Load the saved model\n","    model = XLNetForSequenceClassification.from_pretrained(model_path)\n","    model.eval()  # Set the model to evaluation mode\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        predictions = logits.argmax(-1).numpy()  # Get the predicted class labels\n","        all_predictions.append(predictions)\n","\n","# Convert list of predictions to a NumPy array\n","all_predictions = np.array(all_predictions)\n","\n","# Average the predictions across all folds\n","# Using np.mean with axis=0 to get the mean prediction for each instance\n","average_predictions = np.mean(all_predictions, axis=0)\n","\n","# Convert averaged predictions to class labels\n","# Classify as 'Readmission' if the mean prediction is >= 0.5, else 'No Readmission'\n","final_predictions = [\"Readmission\" if pred >= 0.5 else \"No Readmission\" for pred in average_predictions]\n","\n","# Display results\n","for note, label in zip(clinical_notes, final_predictions):\n","    print(f\"Clinical Note: '{note}' => Predicted Label: '{label}'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YyBbjLYXL7hV","outputId":"ae9e4bd3-331f-4454-eb01-cf8f1eeed1fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Clinical Note: 'The patient is a 65-year-old female with a history of congestive heart failure and chronic obstructive pulmonary disease (COPD). She was admitted for acute exacerbation of COPD, presenting with severe shortness of breath and low oxygen saturation. During her hospital stay, her condition required frequent adjustments to her oxygen therapy and multiple high-dose steroid treatments. The discharge plan included oxygen therapy at home and follow-up in one week. However, she lives alone and expressed concerns about managing her medications and oxygen setup. Her last lab results showed borderline low sodium and elevated blood urea nitrogen, with fluctuating blood pressure readings. She also had a recent hospitalization three weeks ago for a similar issue.' => Predicted Label: 'Readmission'\n","Clinical Note: 'The patient is a 45-year-old male with hypertension and Type 2 diabetes, who was admitted for routine monitoring after an elective orthopedic surgery. His hospital course was stable, with no complications, and he showed consistent improvement in mobility and pain control. Vital signs and lab results were within normal ranges at discharge. He was discharged with a home exercise plan and clear instructions on managing post-operative care, including regular check-ups with his primary physician. He has a strong support system at home, with family members who can assist with his care as needed. No significant health issues were noted at discharge.' => Predicted Label: 'No Readmission'\n","Clinical Note: 'The patient is a 50-year-old male with schizophrenia and Type 2 diabetes, admitted for hyperglycemia and dehydration. He was stabilized with insulin and rehydration during his stay. However, he has a history of non-adherence to medication, which complicates his diabetes management. He is being discharged with insulin therapy and has been referred for mental health follow-up, but he has a limited support system. His lab results at discharge were within normal ranges, but his history of inconsistent medication adherence and frequent admissions suggests a high risk of readmission.' => Predicted Label: 'Readmission'\n","Clinical Note: 'The patient is a 55-year-old female with no significant prior medical history, admitted for knee replacement surgery. Her postoperative recovery was smooth, with no complications, and her vital signs remained stable throughout her stay. Physical therapy sessions showed good progress, and she was discharged with clear instructions for exercises and a follow-up with her orthopedic surgeon in two weeks. She has family support at home, and all necessary pain medications and supplies were arranged prior to discharge. Her final lab results were within normal limits, indicating a low risk of complications.' => Predicted Label: 'No Readmission'\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["56040197cac347b9b06b1127792d7a75","40fdd4f2830a49a5b9a1784ea155281a","f2ca75c0fe624ada9edd085f5a2c2fde","9c2d707dd3bb4b4b84cb2b8e34b07049","795145d3a8c7418394e95b296f2ff93b","8dc7faf30090464e9c8b2ca9cb2dd73a","50d6b5bb0be648c6ad089edbc0d7eb27","9f6a91c046be4117971825da764337cb","c017a03701f14ef5bd2a8ec4a2456fa2","fd12972b43b648d4b5b9235d565cc9fe","e090b0d417b141eba449db76a6597296"]},"id":"AQIHjnEK8d90","outputId":"44177ea9-1bc6-4799-a2f8-14459ab7dbf7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training with hyperparameters: (4, 16, 3e-05)\n","\n","Fold 1/5\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56040197cac347b9b06b1127792d7a75"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='196' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [196/196 10:00, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Fold 2/5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='196' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [196/196 10:04, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Fold 3/5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='196' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [196/196 10:07, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 4/5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='196' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [196/196 09:59, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Fold 5/5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='196' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [196/196 10:03, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Average Metrics for combination 0:\n","Precision: 0.8292\n","Recall: 0.8754\n","F1-score: 0.8418\n","Accuracy: 0.8754\n","\n","Best hyperparameter combination: (4, 16, 3e-05)\n","Best F1-score: 0.8418\n"]}],"source":["import pandas as pd\n","import torch\n","from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import StratifiedKFold\n","from torch.utils.data import Dataset\n","import os\n","import itertools\n","\n","# Load the dataset\n","file_path = '/content/drive/Shared drives/DATA298B/Readmission/Dataset/cleaned_clinical_notes_readmission.csv'\n","data = pd.read_csv(file_path)\n","\n","# Initialize the tokenizer\n","tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n","\n","# Define a custom dataset class with contiguous tensors\n","class ReadmissionDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        # Ensure all tensors in encodings and labels are contiguous\n","        self.encodings = {key: torch.tensor(val).contiguous() for key, val in encodings.items()}\n","        self.labels = torch.tensor(labels).contiguous()\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item['labels'] = self.labels[idx]\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Define hyperparameters to tune\n","hyperparameters = {\n","    'num_train_epochs': [4],\n","    'per_device_train_batch_size': [16],\n","    'learning_rate': [3e-5],\n","}\n","\n","# Create all combinations of hyperparameters\n","param_combinations = list(itertools.product(*hyperparameters.values()))\n","\n","# Stratified cross-validation setup\n","k_folds = 5\n","skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n","metrics_per_combination = {}\n","\n","# Folder to save the model\n","model_save_path = '/content/drive/Shared drives/DATA298B/Readmission/Dataset/saved_model7'\n","os.makedirs(model_save_path, exist_ok=True)\n","\n","# Perform cross-validation with hyperparameter tuning\n","for param_idx, params in enumerate(param_combinations):\n","    print(f\"\\nTraining with hyperparameters: {params}\")\n","\n","    num_train_epochs, per_device_train_batch_size, learning_rate = params\n","    fold_metrics = []\n","\n","    for fold, (train_index, test_index) in enumerate(skf.split(data, data['readmission'])):\n","        print(f\"\\nFold {fold + 1}/{k_folds}\")\n","\n","        # Split the data\n","        train_texts, test_texts = data['clinical_notes'].iloc[train_index].tolist(), data['clinical_notes'].iloc[test_index].tolist()\n","        train_labels, test_labels = data['readmission'].iloc[train_index].tolist(), data['readmission'].iloc[test_index].tolist()\n","\n","        # Tokenize\n","        train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n","        test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)\n","\n","        # Create dataset\n","        train_dataset = ReadmissionDataset(train_encodings, train_labels)\n","        test_dataset = ReadmissionDataset(test_encodings, test_labels)\n","\n","        # Load the model\n","        model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\n","\n","        # Make all model parameters contiguous\n","        for param in model.parameters():\n","            param.data = param.data.contiguous()\n","\n","        # Set up training arguments\n","        training_args = TrainingArguments(\n","            output_dir=f'./results_fold_{fold}',\n","            num_train_epochs=num_train_epochs,\n","            per_device_train_batch_size=per_device_train_batch_size,\n","            per_device_eval_batch_size=16,\n","            learning_rate=learning_rate,\n","            evaluation_strategy=\"no\",\n","            report_to=\"none\",\n","        )\n","\n","        # Define the Trainer\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=test_dataset,\n","        )\n","\n","        # Train the model\n","        trainer.train()\n","\n","        # Save the model after training in each fold\n","        model.save_pretrained(os.path.join(model_save_path, f'model_fold_{fold + 1}_params_{param_idx}'))\n","        tokenizer.save_pretrained(os.path.join(model_save_path, f'model_fold_{fold + 1}_params_{param_idx}'))\n","\n","        # Evaluate the model\n","        predictions = trainer.predict(test_dataset)\n","        pred_labels = predictions.predictions.argmax(-1)\n","\n","        # Calculate metrics\n","        report = classification_report(test_labels, pred_labels, output_dict=True)\n","        fold_metrics.append(report)\n","\n","    # Aggregate metrics for the hyperparameter configuration\n","    avg_metrics = {\n","        \"precision\": sum(d[\"weighted avg\"][\"precision\"] for d in fold_metrics) / k_folds,\n","        \"recall\": sum(d[\"weighted avg\"][\"recall\"] for d in fold_metrics) / k_folds,\n","        \"f1-score\": sum(d[\"weighted avg\"][\"f1-score\"] for d in fold_metrics) / k_folds,\n","        \"accuracy\": sum(d[\"accuracy\"] for d in fold_metrics) / k_folds,\n","    }\n","\n","    metrics_per_combination[param_idx] = avg_metrics\n","    print(f\"\\nAverage Metrics for combination {param_idx}:\")\n","    print(f\"Precision: {avg_metrics['precision']:.4f}\")\n","    print(f\"Recall: {avg_metrics['recall']:.4f}\")\n","    print(f\"F1-score: {avg_metrics['f1-score']:.4f}\")\n","    print(f\"Accuracy: {avg_metrics['accuracy']:.4f}\")\n","\n","# Find the best hyperparameter combination\n","best_combination_idx = max(metrics_per_combination, key=lambda k: metrics_per_combination[k]['f1-score'])\n","best_metrics = metrics_per_combination[best_combination_idx]\n","print(f\"\\nBest hyperparameter combination: {param_combinations[best_combination_idx]}\")\n","print(f\"Best F1-score: {best_metrics['f1-score']:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDLk93cvfE8w","outputId":"6d2bdb39-9bd8-4d31-85fd-f3be3fcd2bc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Clinical Note: 'The patient, identified as a 50-year-old male (Patient ID 10059, Hospital Admission ID 122098), was admitted to our facility on 2000-08-22 under the classification of emergency. The patient presented to the hospital via emergency room admit, indicating a possible referral from another healthcare facility or transfer from emergency services. After completing the necessary course of care, the patient was eventually discharged to home. Their hospital stay was covered under the Medicare insurance plan, which facilitated comprehensive treatment. Upon admission, the primary diagnosis was determined to be lower gi bleed (also referred to as Cirrhosis of liver NOS). Given the severity of the patientâ€™s symptoms, immediate medical attention was required. The patient initially spent approximately 3.083333333333333 hours in the emergency department, during which time they were stabilized and subjected to a range of diagnostic tests. Due to the critical nature of their condition, it was decided that further intensive monitoring and intervention were necessary. The patient was transferred to the carevue ICU, where they remained for 1.7806 days. During their ICU stay, the patient was closely monitored and received the appropriate medical interventions tailored to their condition. Notably, the patient was administered sodium chloride 0.9%  flush, categorized as a MAIN medication, to manage their condition effectively. The medication was delivered via IV, ensuring optimal therapeutic benefit. The prescribed regimen lasted for 6 days, with a total administered dosage amounting to 3.0 units. The choice and administration of this medication were crucial in stabilizing the patient's condition and promoting recovery. The patient remained in the hospital for a total of 7 days, during which time their progress was closely monitored. Upon discharge, the patient was deemed stable and capable of continuing recovery at home. This suggests that the initial treatment plan was effective and that the patient adhered well to post-discharge care protocols. Overall, the patient responded positively to the interventions provided during their stay, and their eventual discharge was a result of significant clinical improvement. Ongoing outpatient follow-up will ensure that any further complications are addressed promptly.' => Predicted Label: 'Readmission'\n","Clinical Note: 'The patient, identified as a 70-year-old male (Patient ID 10094, Hospital Admission ID 122928), was admitted to our facility on 2020-03-15 under the classification of emergency. The patient presented to the hospital via emergency room admit, indicating a possible referral from another healthcare facility or transfer from emergency services. After completing the necessary course of care, the patient was eventually discharged to home. Their hospital stay was covered under the Medicare insurance plan, which facilitated comprehensive treatment. Upon admission, the primary diagnosis was determined to be sepsis;telemetry (also referred to as Septicemia NOS). Given the severity of the patientâ€™s symptoms, immediate medical attention was required. The patient initially spent approximately 7.733333333333333 hours in the emergency department, during which time they were stabilized and subjected to a range of diagnostic tests. Due to the critical nature of their condition, it was decided that further intensive monitoring and intervention were necessary. The patient was transferred to the carevue ICU, where they remained for 4.1014 days. During their ICU stay, the patient was closely monitored and received the appropriate medical interventions tailored to their condition. Notably, the patient was administered prednisone, categorized as a MAIN medication, to manage their condition effectively. The medication was delivered via PO, ensuring optimal therapeutic benefit. The prescribed regimen lasted for 1 days, with a total administered dosage amounting to 5.0 units. The choice and administration of this medication were crucial in stabilizing the patient's condition and promoting recovery. The patient remained in the hospital for a total of 5 days, during which time their progress was closely monitored. Upon discharge, the patient was deemed stable and capable of continuing recovery at home. This suggests that the initial treatment plan was effective and that the patient adhered well to post-discharge care protocols. Overall, the patient responded positively to the interventions provided during their stay, and their eventual discharge was a result of significant clinical improvement. Ongoing outpatient follow-up will ensure that any further complications are addressed promptly.' => Predicted Label: 'Readmission'\n"]}],"source":["import torch\n","import numpy as np\n","from transformers import XLNetTokenizer, XLNetForSequenceClassification\n","\n","# Specify the number of folds\n","num_folds = 5  # Adjust this based on the number of folds used during training\n","model_paths = [f'/content/drive/Shared drives/DATA298B/Readmission/Dataset/saved_model5/model_fold_{i+1}_params_0' for i in range(num_folds)]\n","\n","# Load the tokenizer\n","tokenizer = XLNetTokenizer.from_pretrained(model_paths[0])  # Use the tokenizer from any model\n","\n","# Example clinical notes for prediction\n","clinical_notes = [\n","\n","                  \"The patient, identified as a 50-year-old male (Patient ID 10059, Hospital Admission ID 122098), was admitted to our facility on 2000-08-22 under the classification of emergency. The patient presented to the hospital via emergency room admit, indicating a possible referral from another healthcare facility or transfer from emergency services. After completing the necessary course of care, the patient was eventually discharged to home. Their hospital stay was covered under the Medicare insurance plan, which facilitated comprehensive treatment. Upon admission, the primary diagnosis was determined to be lower gi bleed (also referred to as Cirrhosis of liver NOS). Given the severity of the patientâ€™s symptoms, immediate medical attention was required. The patient initially spent approximately 3.083333333333333 hours in the emergency department, during which time they were stabilized and subjected to a range of diagnostic tests. Due to the critical nature of their condition, it was decided that further intensive monitoring and intervention were necessary. The patient was transferred to the carevue ICU, where they remained for 1.7806 days. During their ICU stay, the patient was closely monitored and received the appropriate medical interventions tailored to their condition. Notably, the patient was administered sodium chloride 0.9%  flush, categorized as a MAIN medication, to manage their condition effectively. The medication was delivered via IV, ensuring optimal therapeutic benefit. The prescribed regimen lasted for 6 days, with a total administered dosage amounting to 3.0 units. The choice and administration of this medication were crucial in stabilizing the patient's condition and promoting recovery. The patient remained in the hospital for a total of 7 days, during which time their progress was closely monitored. Upon discharge, the patient was deemed stable and capable of continuing recovery at home. This suggests that the initial treatment plan was effective and that the patient adhered well to post-discharge care protocols. Overall, the patient responded positively to the interventions provided during their stay, and their eventual discharge was a result of significant clinical improvement. Ongoing outpatient follow-up will ensure that any further complications are addressed promptly.\",\n","                  \"The patient, identified as a 70-year-old male (Patient ID 10094, Hospital Admission ID 122928), was admitted to our facility on 2020-03-15 under the classification of emergency. The patient presented to the hospital via emergency room admit, indicating a possible referral from another healthcare facility or transfer from emergency services. After completing the necessary course of care, the patient was eventually discharged to home. Their hospital stay was covered under the Medicare insurance plan, which facilitated comprehensive treatment. Upon admission, the primary diagnosis was determined to be sepsis;telemetry (also referred to as Septicemia NOS). Given the severity of the patientâ€™s symptoms, immediate medical attention was required. The patient initially spent approximately 7.733333333333333 hours in the emergency department, during which time they were stabilized and subjected to a range of diagnostic tests. Due to the critical nature of their condition, it was decided that further intensive monitoring and intervention were necessary. The patient was transferred to the carevue ICU, where they remained for 4.1014 days. During their ICU stay, the patient was closely monitored and received the appropriate medical interventions tailored to their condition. Notably, the patient was administered prednisone, categorized as a MAIN medication, to manage their condition effectively. The medication was delivered via PO, ensuring optimal therapeutic benefit. The prescribed regimen lasted for 1 days, with a total administered dosage amounting to 5.0 units. The choice and administration of this medication were crucial in stabilizing the patient's condition and promoting recovery. The patient remained in the hospital for a total of 5 days, during which time their progress was closely monitored. Upon discharge, the patient was deemed stable and capable of continuing recovery at home. This suggests that the initial treatment plan was effective and that the patient adhered well to post-discharge care protocols. Overall, the patient responded positively to the interventions provided during their stay, and their eventual discharge was a result of significant clinical improvement. Ongoing outpatient follow-up will ensure that any further complications are addressed promptly.\"\n","]\n","\n","# Prepare inputs for the model\n","inputs = tokenizer(clinical_notes, truncation=True, max_length=512, padding=True, return_tensors='pt')\n","\n","# List to store predictions from each fold\n","all_predictions = []\n","\n","# Make predictions using each model\n","for model_path in model_paths:\n","    # Load the saved model\n","    model = XLNetForSequenceClassification.from_pretrained(model_path)\n","    model.eval()  # Set the model to evaluation mode\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        predictions = logits.argmax(-1).numpy()  # Get the predicted class labels\n","        all_predictions.append(predictions)\n","\n","# Convert list of predictions to a NumPy array\n","all_predictions = np.array(all_predictions)\n","\n","# Average the predictions across all folds\n","# Using np.mean with axis=0 to get the mean prediction for each instance\n","average_predictions = np.mean(all_predictions, axis=0)\n","\n","# Convert averaged predictions to class labels\n","# Classify as 'Readmission' if the mean prediction is >= 0.5, else 'No Readmission'\n","final_predictions = [\"Readmission\" if pred >= 0.5 else \"No Readmission\" for pred in average_predictions]\n","\n","# Display results\n","for note, label in zip(clinical_notes, final_predictions):\n","    print(f\"Clinical Note: '{note}' => Predicted Label: '{label}'\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"mAet4AGDx2PF","outputId":"64c57c17-bb7e-41ad-9ba9-b5668dcea621"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","Training with hyperparameters: (4, 8, 3e-05)\n","\n","Fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='392' max='392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [392/392 09:28, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='392' max='392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [392/392 09:32, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='392' max='392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [392/392 09:31, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='392' max='392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [392/392 09:26, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='392' max='392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [392/392 09:37, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Average Metrics for combination 0:\n","Precision: 0.9980\n","Recall: 0.9979\n","F1-score: 0.9979\n","Accuracy: 0.9979\n","\n","Best hyperparameter combination: (4, 8, 3e-05)\n","Best F1-score: 0.9979\n"]}],"source":["import pandas as pd\n","import torch\n","from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import StratifiedKFold\n","from torch.utils.data import Dataset\n","import os\n","import itertools\n","\n","# Load the dataset\n","file_path = '/content/drive/Shared drives/DATA298B/Readmission/Dataset/cleaned_clinical_notes_readmission.csv'\n","data = pd.read_csv(file_path)\n","\n","# Initialize the tokenizer\n","tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n","\n","# Define a custom dataset class with contiguous tensors\n","class ReadmissionDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        # Ensure all tensors in encodings and labels are contiguous\n","        self.encodings = {key: torch.tensor(val).contiguous() for key, val in encodings.items()}\n","        self.labels = torch.tensor(labels).contiguous()\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item['labels'] = self.labels[idx]\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Define hyperparameters to tune\n","hyperparameters = {\n","    'num_train_epochs': [4],\n","    'per_device_train_batch_size': [8],\n","    'learning_rate': [3e-5],\n","}\n","\n","# Create all combinations of hyperparameters\n","param_combinations = list(itertools.product(*hyperparameters.values()))\n","\n","# Stratified cross-validation setup\n","k_folds = 5\n","skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n","metrics_per_combination = {}\n","\n","# Folder to save the model\n","model_save_path = '/content/drive/Shared drives/DATA298B/Readmission/Dataset/saved_model6'\n","os.makedirs(model_save_path, exist_ok=True)\n","\n","# Perform cross-validation with hyperparameter tuning\n","for param_idx, params in enumerate(param_combinations):\n","    print(f\"\\nTraining with hyperparameters: {params}\")\n","\n","    num_train_epochs, per_device_train_batch_size, learning_rate = params\n","    fold_metrics = []\n","\n","    for fold, (train_index, test_index) in enumerate(skf.split(data, data['readmission'])):\n","        print(f\"\\nFold {fold + 1}/{k_folds}\")\n","\n","        # Split the data\n","        train_texts, test_texts = data['clinical_notes'].iloc[train_index].tolist(), data['clinical_notes'].iloc[test_index].tolist()\n","        train_labels, test_labels = data['readmission'].iloc[train_index].tolist(), data['readmission'].iloc[test_index].tolist()\n","\n","        # Tokenize\n","        train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n","        test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)\n","\n","        # Create dataset\n","        train_dataset = ReadmissionDataset(train_encodings, train_labels)\n","        test_dataset = ReadmissionDataset(test_encodings, test_labels)\n","\n","        # Load the model\n","        model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\n","\n","        # Make all model parameters contiguous\n","        for param in model.parameters():\n","            param.data = param.data.contiguous()\n","\n","        # Set up training arguments\n","        training_args = TrainingArguments(\n","            output_dir=f'./results_fold_{fold}',\n","            num_train_epochs=num_train_epochs,\n","            per_device_train_batch_size=per_device_train_batch_size,\n","            per_device_eval_batch_size=16,\n","            learning_rate=learning_rate,\n","            evaluation_strategy=\"no\",\n","            report_to=\"none\",\n","        )\n","\n","        # Define the Trainer\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=test_dataset,\n","        )\n","\n","        # Train the model\n","        trainer.train()\n","\n","        # Save the model after training in each fold\n","        model.save_pretrained(os.path.join(model_save_path, f'model_fold_{fold + 1}_params_{param_idx}'))\n","        tokenizer.save_pretrained(os.path.join(model_save_path, f'model_fold_{fold + 1}_params_{param_idx}'))\n","\n","        # Evaluate the model\n","        predictions = trainer.predict(test_dataset)\n","        pred_labels = predictions.predictions.argmax(-1)\n","\n","        # Calculate metrics\n","        report = classification_report(test_labels, pred_labels, output_dict=True)\n","        fold_metrics.append(report)\n","\n","    # Aggregate metrics for the hyperparameter configuration\n","    avg_metrics = {\n","        \"precision\": sum(d[\"weighted avg\"][\"precision\"] for d in fold_metrics) / k_folds,\n","        \"recall\": sum(d[\"weighted avg\"][\"recall\"] for d in fold_metrics) / k_folds,\n","        \"f1-score\": sum(d[\"weighted avg\"][\"f1-score\"] for d in fold_metrics) / k_folds,\n","        \"accuracy\": sum(d[\"accuracy\"] for d in fold_metrics) / k_folds,\n","    }\n","\n","    metrics_per_combination[param_idx] = avg_metrics\n","    print(f\"\\nAverage Metrics for combination {param_idx}:\")\n","    print(f\"Precision: {avg_metrics['precision']:.4f}\")\n","    print(f\"Recall: {avg_metrics['recall']:.4f}\")\n","    print(f\"F1-score: {avg_metrics['f1-score']:.4f}\")\n","    print(f\"Accuracy: {avg_metrics['accuracy']:.4f}\")\n","\n","# Find the best hyperparameter combination\n","best_combination_idx = max(metrics_per_combination, key=lambda k: metrics_per_combination[k]['f1-score'])\n","best_metrics = metrics_per_combination[best_combination_idx]\n","print(f\"\\nBest hyperparameter combination: {param_combinations[best_combination_idx]}\")\n","print(f\"Best F1-score: {best_metrics['f1-score']:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FSGlSqTE4N2k","outputId":"47ef3a52-7c8f-4b80-f027-23990220f8fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Clinical Note: 'The patient, identified as a 50-year-old male (Patient ID 10059, Hospital Admission ID 122098), was admitted to our facility on 2000-08-22 under the classification of emergency. The patient presented to the hospital via emergency room admit, indicating a possible referral from another healthcare facility or transfer from emergency services. After completing the necessary course of care, the patient was eventually discharged to home. Their hospital stay was covered under the Medicare insurance plan, which facilitated comprehensive treatment. Upon admission, the primary diagnosis was determined to be lower gi bleed (also referred to as Cirrhosis of liver NOS). Given the severity of the patientâ€™s symptoms, immediate medical attention was required. The patient initially spent approximately 3.083333333333333 hours in the emergency department, during which time they were stabilized and subjected to a range of diagnostic tests. Due to the critical nature of their condition, it was decided that further intensive monitoring and intervention were necessary. The patient was transferred to the carevue ICU, where they remained for 1.7806 days. During their ICU stay, the patient was closely monitored and received the appropriate medical interventions tailored to their condition. Notably, the patient was administered sodium chloride 0.9%  flush, categorized as a MAIN medication, to manage their condition effectively. The medication was delivered via IV, ensuring optimal therapeutic benefit. The prescribed regimen lasted for 6 days, with a total administered dosage amounting to 3.0 units. The choice and administration of this medication were crucial in stabilizing the patient's condition and promoting recovery. The patient remained in the hospital for a total of 7 days, during which time their progress was closely monitored. Upon discharge, the patient was deemed stable and capable of continuing recovery at home. This suggests that the initial treatment plan was effective and that the patient adhered well to post-discharge care protocols. Overall, the patient responded positively to the interventions provided during their stay, and their eventual discharge was a result of significant clinical improvement. Ongoing outpatient follow-up will ensure that any further complications are addressed promptly.' => Predicted Label: 'Readmission'\n","Clinical Note: 'The patient, identified as a 70-year-old male (Patient ID 10094, Hospital Admission ID 122928), was admitted to our facility on 2020-03-15 under the classification of emergency. The patient presented to the hospital via emergency room admit, indicating a possible referral from another healthcare facility or transfer from emergency services. After completing the necessary course of care, the patient was eventually discharged to home. Their hospital stay was covered under the Medicare insurance plan, which facilitated comprehensive treatment. Upon admission, the primary diagnosis was determined to be sepsis;telemetry (also referred to as Septicemia NOS). Given the severity of the patientâ€™s symptoms, immediate medical attention was required. The patient initially spent approximately 7.733333333333333 hours in the emergency department, during which time they were stabilized and subjected to a range of diagnostic tests. Due to the critical nature of their condition, it was decided that further intensive monitoring and intervention were necessary. The patient was transferred to the carevue ICU, where they remained for 4.1014 days. During their ICU stay, the patient was closely monitored and received the appropriate medical interventions tailored to their condition. Notably, the patient was administered prednisone, categorized as a MAIN medication, to manage their condition effectively. The medication was delivered via PO, ensuring optimal therapeutic benefit. The prescribed regimen lasted for 1 days, with a total administered dosage amounting to 5.0 units. The choice and administration of this medication were crucial in stabilizing the patient's condition and promoting recovery. The patient remained in the hospital for a total of 5 days, during which time their progress was closely monitored. Upon discharge, the patient was deemed stable and capable of continuing recovery at home. This suggests that the initial treatment plan was effective and that the patient adhered well to post-discharge care protocols. Overall, the patient responded positively to the interventions provided during their stay, and their eventual discharge was a result of significant clinical improvement. Ongoing outpatient follow-up will ensure that any further complications are addressed promptly.' => Predicted Label: 'Readmission'\n"]}],"source":["import torch\n","import numpy as np\n","from transformers import XLNetTokenizer, XLNetForSequenceClassification\n","\n","# Specify the number of folds\n","num_folds = 5  # Adjust this based on the number of folds used during training\n","model_paths = [f'/content/drive/Shared drives/DATA298B/Readmission/Dataset/saved_model6/model_fold_{i+1}_params_0' for i in range(num_folds)]\n","\n","# Load the tokenizer\n","tokenizer = XLNetTokenizer.from_pretrained(model_paths[0])  # Use the tokenizer from any model\n","\n","# Example clinical notes for prediction\n","clinical_notes = [\n","\n","                  \"The patient, identified as a 50-year-old male (Patient ID 10059, Hospital Admission ID 122098), was admitted to our facility on 2000-08-22 under the classification of emergency. The patient presented to the hospital via emergency room admit, indicating a possible referral from another healthcare facility or transfer from emergency services. After completing the necessary course of care, the patient was eventually discharged to home. Their hospital stay was covered under the Medicare insurance plan, which facilitated comprehensive treatment. Upon admission, the primary diagnosis was determined to be lower gi bleed (also referred to as Cirrhosis of liver NOS). Given the severity of the patientâ€™s symptoms, immediate medical attention was required. The patient initially spent approximately 3.083333333333333 hours in the emergency department, during which time they were stabilized and subjected to a range of diagnostic tests. Due to the critical nature of their condition, it was decided that further intensive monitoring and intervention were necessary. The patient was transferred to the carevue ICU, where they remained for 1.7806 days. During their ICU stay, the patient was closely monitored and received the appropriate medical interventions tailored to their condition. Notably, the patient was administered sodium chloride 0.9%  flush, categorized as a MAIN medication, to manage their condition effectively. The medication was delivered via IV, ensuring optimal therapeutic benefit. The prescribed regimen lasted for 6 days, with a total administered dosage amounting to 3.0 units. The choice and administration of this medication were crucial in stabilizing the patient's condition and promoting recovery. The patient remained in the hospital for a total of 7 days, during which time their progress was closely monitored. Upon discharge, the patient was deemed stable and capable of continuing recovery at home. This suggests that the initial treatment plan was effective and that the patient adhered well to post-discharge care protocols. Overall, the patient responded positively to the interventions provided during their stay, and their eventual discharge was a result of significant clinical improvement. Ongoing outpatient follow-up will ensure that any further complications are addressed promptly.\",\n","                  \"The patient, identified as a 70-year-old male (Patient ID 10094, Hospital Admission ID 122928), was admitted to our facility on 2020-03-15 under the classification of emergency. The patient presented to the hospital via emergency room admit, indicating a possible referral from another healthcare facility or transfer from emergency services. After completing the necessary course of care, the patient was eventually discharged to home. Their hospital stay was covered under the Medicare insurance plan, which facilitated comprehensive treatment. Upon admission, the primary diagnosis was determined to be sepsis;telemetry (also referred to as Septicemia NOS). Given the severity of the patientâ€™s symptoms, immediate medical attention was required. The patient initially spent approximately 7.733333333333333 hours in the emergency department, during which time they were stabilized and subjected to a range of diagnostic tests. Due to the critical nature of their condition, it was decided that further intensive monitoring and intervention were necessary. The patient was transferred to the carevue ICU, where they remained for 4.1014 days. During their ICU stay, the patient was closely monitored and received the appropriate medical interventions tailored to their condition. Notably, the patient was administered prednisone, categorized as a MAIN medication, to manage their condition effectively. The medication was delivered via PO, ensuring optimal therapeutic benefit. The prescribed regimen lasted for 1 days, with a total administered dosage amounting to 5.0 units. The choice and administration of this medication were crucial in stabilizing the patient's condition and promoting recovery. The patient remained in the hospital for a total of 5 days, during which time their progress was closely monitored. Upon discharge, the patient was deemed stable and capable of continuing recovery at home. This suggests that the initial treatment plan was effective and that the patient adhered well to post-discharge care protocols. Overall, the patient responded positively to the interventions provided during their stay, and their eventual discharge was a result of significant clinical improvement. Ongoing outpatient follow-up will ensure that any further complications are addressed promptly.\"\n","]\n","\n","# Prepare inputs for the model\n","inputs = tokenizer(clinical_notes, truncation=True, max_length=512, padding=True, return_tensors='pt')\n","\n","# List to store predictions from each fold\n","all_predictions = []\n","\n","# Make predictions using each model\n","for model_path in model_paths:\n","    # Load the saved model\n","    model = XLNetForSequenceClassification.from_pretrained(model_path)\n","    model.eval()  # Set the model to evaluation mode\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        predictions = logits.argmax(-1).numpy()  # Get the predicted class labels\n","        all_predictions.append(predictions)\n","\n","# Convert list of predictions to a NumPy array\n","all_predictions = np.array(all_predictions)\n","\n","# Average the predictions across all folds\n","# Using np.mean with axis=0 to get the mean prediction for each instance\n","average_predictions = np.mean(all_predictions, axis=0)\n","\n","# Convert averaged predictions to class labels\n","# Classify as 'Readmission' if the mean prediction is >= 0.5, else 'No Readmission'\n","final_predictions = [\"Readmission\" if pred >= 0.5 else \"No Readmission\" for pred in average_predictions]\n","\n","# Display results\n","for note, label in zip(clinical_notes, final_predictions):\n","    print(f\"Clinical Note: '{note}' => Predicted Label: '{label}'\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ee71f39634984fb38c0464a01377e65c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_190d0599a94a48349b0cd42873d0970f","IPY_MODEL_8bbb9f5deead4dbb988fae51643a902c","IPY_MODEL_47ad6c09ff844505bc859fe5abf8bd79"],"layout":"IPY_MODEL_b01d09cb75174a4cbef9694589123cef"}},"190d0599a94a48349b0cd42873d0970f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cac1c701e1a443b889fc2ea8b156b0ce","placeholder":"â€‹","style":"IPY_MODEL_cf0c19da28994ca4a8be500b605668c3","value":"pytorch_model.bin:â€‡100%"}},"8bbb9f5deead4dbb988fae51643a902c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d27f9dd6e304c498755b0d9e334358b","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a647b4e69b64f258bb111c55158e358","value":467042463}},"47ad6c09ff844505bc859fe5abf8bd79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_956fd3b66904427db3d419540140a30b","placeholder":"â€‹","style":"IPY_MODEL_e71536b652ab4b34ad6dde342b4c0aa0","value":"â€‡467M/467Mâ€‡[00:02&lt;00:00,â€‡199MB/s]"}},"b01d09cb75174a4cbef9694589123cef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cac1c701e1a443b889fc2ea8b156b0ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf0c19da28994ca4a8be500b605668c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d27f9dd6e304c498755b0d9e334358b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a647b4e69b64f258bb111c55158e358":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"956fd3b66904427db3d419540140a30b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e71536b652ab4b34ad6dde342b4c0aa0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56040197cac347b9b06b1127792d7a75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40fdd4f2830a49a5b9a1784ea155281a","IPY_MODEL_f2ca75c0fe624ada9edd085f5a2c2fde","IPY_MODEL_9c2d707dd3bb4b4b84cb2b8e34b07049"],"layout":"IPY_MODEL_795145d3a8c7418394e95b296f2ff93b"}},"40fdd4f2830a49a5b9a1784ea155281a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dc7faf30090464e9c8b2ca9cb2dd73a","placeholder":"â€‹","style":"IPY_MODEL_50d6b5bb0be648c6ad089edbc0d7eb27","value":"pytorch_model.bin:â€‡100%"}},"f2ca75c0fe624ada9edd085f5a2c2fde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f6a91c046be4117971825da764337cb","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c017a03701f14ef5bd2a8ec4a2456fa2","value":467042463}},"9c2d707dd3bb4b4b84cb2b8e34b07049":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd12972b43b648d4b5b9235d565cc9fe","placeholder":"â€‹","style":"IPY_MODEL_e090b0d417b141eba449db76a6597296","value":"â€‡467M/467Mâ€‡[00:03&lt;00:00,â€‡133MB/s]"}},"795145d3a8c7418394e95b296f2ff93b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dc7faf30090464e9c8b2ca9cb2dd73a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50d6b5bb0be648c6ad089edbc0d7eb27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f6a91c046be4117971825da764337cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c017a03701f14ef5bd2a8ec4a2456fa2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd12972b43b648d4b5b9235d565cc9fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e090b0d417b141eba449db76a6597296":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}